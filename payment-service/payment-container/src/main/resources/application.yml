server:
  port: 8182

payment-service:
  customer-event:
    consumer-group-id: customer-event-topic-consumer
    topic-name: customer-event
  payment:
    consumer-group-id: payment-request-topic-consumer
    request-topic-name: payment-request
    response-topic-name: payment-response

spring:
  main:
    banner-mode: off
  jpa:
    # defer-datasource-initialization: true
    open-in-view: false
    show-sql: false
    database-platform: org.hibernate.dialect.PostgreSQLDialect
    properties:
      default_schema: payment
      hibernate:
        dialect: org.hibernate.dialect.PostgreSQLDialect
  datasource:
    url: jdbc:postgresql://localhost:5432/postgres?currentSchema=payment&binaryTransfer=true&reWriteBatchedInserts=true&stringType=unspecified
    username: postgres
    password: ""
    driver-class-name: org.postgresql.Driver
  sql:
    init:
      platform: postgres
      mode: always
  liquibase:
    change-log: "classpath:db/changelog/changelog-master.yaml"
    default-schema: payment
  security:
    oauth2:
      client:
        registration:
          keycloak:
            client-id: ticketing-login
            authorization-grant-type: authorization_code
            scope: openid
        provider:
          keycloak:
            issuer-uri: http://localhost:8080/realms/acroteq
            user-name-attribute: preferred_username
      resourceserver:
        jwt:
          issuer-uri: http://localhost:8080/realms/acroteq
  kafka:
    bootstrap-servers: localhost:19093
    security:
      protocol: "SSL"
    ssl:
      key-store-location: file:infrastructure/docker-compose/kafka/certs/payment-service/payment-service.keystore.jks
      key-store-password: acroteq
      trust-store-location: file:infrastructure/docker-compose/kafka/certs/payment-service/payment-service.truststore.jks
      trust-store-password: acroteq
    producer:
      acks: all
      batch-size: 16384
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
      compression-type: snappy
      retries: 5
      properties:
        linger.ms: 5
        schema.registry.url: http://localhost:8081
        ssl.endpoint.identification.algorithm: ""
    listener:
      type: batch
      ack-mode: batch
      concurrency: 1
      poll-timeout: 150
    consumer:
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
      heartbeat-interval: 3000
      max-poll-records: 500
      properties:
        schema.registry.url: http://localhost:8081
        value.subject.name.strategy: io.confluent.kafka.serializers.subject.TopicRecordNameStrategy
        specific.avro.reader: true
        session.timeout.ms: 60000
        max.poll.interval.ms: 10000
        max.partition.fetch.bytes: 1048576
        max.poll.records: 10
        ssl.endpoint.identification.algorithm: ""

kafka:
  consumer:
    dead-letter:
      suffix: -dlt
    backoff:
      max-retries: 3
      initial-interval-in-seconds: 10
      multiplier: 2
      max-interval-in-seconds: 40
